{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e6661e8",
   "metadata": {},
   "source": [
    "# Install dependencies in a virtual environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c2b061",
   "metadata": {},
   "source": [
    "Install packages for efficiently parsing CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0b0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install casanova"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09059b10",
   "metadata": {},
   "source": [
    "Install packages for NLP analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9633ede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bertopic hdbscan nltk sentence_transformers scikit-learn umap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7165cb01",
   "metadata": {},
   "source": [
    "Also install `protobuf` version 3.20 because `SentenceTransformer` needs it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9030ebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install protobuf==3.20.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e3f8c6",
   "metadata": {},
   "source": [
    "Install tools for visualizing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6104a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install networkx ipysigma plotly install pelote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eccb4de",
   "metadata": {},
   "source": [
    "# Prepare data\n",
    "\n",
    "We're going to be taking advantage of transformers and word-embedding, which in theory do not require pre-processing sentences that are sent to the topic model. Nevertheless, some pre-processing can be useful (i.e. removing HTML tags). In our case, we will want to remove the phrase \"Il faut\" at the start of every proposition because it is not meaningful in the context of our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe952b2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATAFILE = \"mieux-sinformer.csv\" # change this according to file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90f639fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def special_preprocessing(string):\n",
    "    string = string.lower()\n",
    "    bow = string.split()\n",
    "    if bow[:2] == [\"il\", \"faut\"]:\n",
    "        bow = bow[2:]\n",
    "    return \" \".join(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32916727",
   "metadata": {},
   "source": [
    "With that helper function in place, we'll parse our data file and create a list of our documents. (list of strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "451f8f26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset includes 1723 docs.\n"
     ]
    }
   ],
   "source": [
    "import casanova\n",
    "\n",
    "with open(DATAFILE) as f:\n",
    "    reader = casanova.reader(f)\n",
    "    docs = [special_preprocessing(cell) for cell in reader.cells(column=\"Proposition\")]\n",
    "    print(f\"Dataset includes {len(docs)} docs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d499a96",
   "metadata": {},
   "source": [
    "We will also need to prepare a list of stop words, which will be excluded from the topics' representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40f2abbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stoplist = stopwords.words(\"french\")\n",
    "ADDITIONAL_STOPWORDS = [\"plus\", \"chaque\", \"tout\", \"tous\", \"toutes\", \"toute\", \"leur\", \"leurs\", \"comme\", \"afin\", \"pendant\", \"lorsque\"]\n",
    "stoplist.extend(ADDITIONAL_STOPWORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98236674",
   "metadata": {},
   "source": [
    "# Vectorize the data\n",
    "\n",
    "### Word embeddings\n",
    "The first step is to transform a string (sentence) into an array of numbers (vector) or in other words, to \"vectorize\" the text. There are many ways to do this. By default, `BERTopic`'s privileges word embeddings, which are currently the most powerful way to encode a document because they represent words' relationships to other words in the context of a sentence.\n",
    "\n",
    "However, `BERTopic`'s default sentence transformer was trained on English-language texts. Because we are working with a corpus of sentences exclusively in French, we want to take advantage of a language model trained on French-language texts, such as the `CamemBERT` model. Fortunately, a data scientist at *La Javaness* Van Tuan Dang (\"dangvantuan\" on HuggingFace) has trained and published a sentence transformer model based on the `CamemBERT` base model. We will simply import this pre-trained transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17030859",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/kelly.christensen/.cache/torch/sentence_transformers/dangvantuan_sentence-camembert-large. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33d1bd70044490f941de168afceaa58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1 has 22 characters, and the embedding is 1024 long.\n",
      "Sentence 2 has 7 characters, and the embedding is 1024 long.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sentences = ['Bonjour tout le monde.', 'Ça va ?']\n",
    "\n",
    "camembert_sentence_transformer = SentenceTransformer(\"dangvantuan/sentence-camembert-large\")\n",
    "example_embeddings = camembert_sentence_transformer.encode(sentences, show_progress_bar=True)\n",
    "\n",
    "print(f\"Sentence 1 has {len(sentences[0])} characters, and the embedding is {len(example_embeddings[0])} long.\")\n",
    "print(f\"Sentence 2 has {len(sentences[1])} characters, and the embedding is {len(example_embeddings[1])} long.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736b35d2",
   "metadata": {},
   "source": [
    "As seen in the cell above, the embeddings created by Dang's sentence transformer `sentence-camembert-large` have the same length, despite the fact that the sentences the arrays represent are different lenghts. The embeddings have the same length because, rather than directly representing words as numbers (aka bag of words), the transformer creates a rich representation that takes into account 1024 dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f185f96",
   "metadata": {},
   "source": [
    "### Construct the topic model with the desired parameters\n",
    "\n",
    "Finally, having decided on an effective embedding model (very important!) and produced stop words for the topics' representations, we're ready to assemble the topic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90258ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic import BERTopic\n",
    "\n",
    "stoplist = stopwords.words(\"french\")\n",
    "ADDITIONAL_STOPWORDS = [\"plus\", \"chaque\", \"tout\", \"tous\", \"toutes\", \"toute\", \"leur\", \"leurs\", \"comme\", \"afin\", \"pendant\", \"lorsque\"]\n",
    "\n",
    "def set_model_parameters(embedding_model):\n",
    "\n",
    "    # Step 1 - Extract embeddings\n",
    "    embedding_model = embedding_model\n",
    "\n",
    "    # Step 2 - Reduce dimensionality\n",
    "    umap_model = UMAP(angular_rp_forest=True, metric='cosine', n_components=10, n_neighbors=30, min_dist=0.1)\n",
    "\n",
    "    # Step 3 - Cluster reduced embeddings\n",
    "    hdbscan_model = HDBSCAN(min_cluster_size=13, min_samples=3, prediction_data=True, metric='euclidean', cluster_selection_method='eom')\n",
    "\n",
    "    # Step 4 - Tokenize topics\n",
    "    stoplist.extend(ADDITIONAL_STOPWORDS)\n",
    "    vectorizer_model = CountVectorizer(stop_words=stoplist, ngram_range=(1, 3))\n",
    "\n",
    "    # Step 5 - Create topic representation\n",
    "    ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True, bm25_weighting=True)\n",
    "\n",
    "    # Topic model\n",
    "    return BERTopic(\n",
    "        embedding_model=embedding_model,\n",
    "        umap_model=umap_model,\n",
    "        hdbscan_model=hdbscan_model,\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        ctfidf_model=ctfidf_model,\n",
    "        diversity=0.5,\n",
    "        n_gram_range=(1,3),\n",
    "        nr_topics='auto'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf00dd83",
   "metadata": {},
   "source": [
    "# Fit the topic model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2be5a1",
   "metadata": {},
   "source": [
    "Download the pre-trained embedding model from `SentenceTransformers` and attribute it to the variable `embedding model`. Then use that model to encode all the documents in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb4b5c7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/kelly.christensen/.cache/torch/sentence_transformers/dangvantuan_sentence-camembert-large. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'camembert_sentence_transformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m      3\u001b[0m embedding_model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdangvantuan/sentence-camembert-large\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mcamembert_sentence_transformer\u001b[49m\u001b[38;5;241m.\u001b[39mencode(docs, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'camembert_sentence_transformer' is not defined"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(\"dangvantuan/sentence-camembert-large\")\n",
    "embeddings = camembert_sentence_transformer.encode(docs, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75196a5c",
   "metadata": {},
   "source": [
    "Create an instance of the model with all the parameters defined and our selected embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d605d27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topic_model = set_model_parameters(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546f4816",
   "metadata": {},
   "source": [
    "Fit the model to the documents in our corpus and to the embeddings we prepared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "773525a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bertopic._bertopic.BERTopic at 0x3febfead0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.fit(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c5842f10-5856-48e9-8e29-c0e2f678752c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-1  --  éducation médias  --  jeunes  --  donner  --  citoyens  --  informer',\n",
       " '0  --  financement  --  concentration médias  --  milliardaires  --  indépendants  --  indépendance médias',\n",
       " '1  --  fake news  --  vérifiée  --  qualité  --  plusieurs  --  sources information',\n",
       " '2  --  réseaux sociaux  --  éducation médias information  --  professeurs documentalistes  --  facebook  --  responsables',\n",
       " '3  --  experts  --  opinion  --  différence entre  --  pensée  --  gauche',\n",
       " '4  --  sujets  --  buzz  --  faits divers  --  jt  --  info',\n",
       " '5  --  analyser  --  école  --  apprendre  --  jeune âge  --  développer',\n",
       " '6  --  arrêtent  --  conditionnel  --  sans  --  être  --  essaient',\n",
       " '7  --  presse  --  acheter  --  rendre accessible  --  papier  --  gratuité',\n",
       " '8  --  continu  --  ue  --  chaînes information  --  belges  --  affranchir',\n",
       " '9  --  auteurs  --  financièrement  --  amendes  --  diffusant  --  élus',\n",
       " '10  --  éthique  --  charte munich  --  conseil déontologie  --  médecins  --  code déontologie',\n",
       " '11  --  anonymat réseaux sociaux  --  réseaux sociaux interdire  --  sociaux interdire  --  supprimer  --  vrai nom',\n",
       " '12  --  sanctionner youtube lorsqu  --  pubs arnaques  --  médias informations  --  influenceurs  --  pub institutionnelles dénoncer',\n",
       " '13  --  médias locaux  --  france  --  national européen laisser  --  nationales internationales publier  --  niveau local retrouver',\n",
       " '14  --  dès école maternelle  --  permettre enfants  --  psycho  --  éducation civique  --  éducation nationale',\n",
       " '15  --  analyser mieux  --  suivi  --  scientifiques  --  peut perdre  --  petit récapitulatif temps',\n",
       " '16  --  emploi temps élèves  --  élèves  --  donner moyens professeurs  --  documentalistes enseigner emi  --  enseignement emi professeurs']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.generate_topic_labels(nr_words=5, topic_prefix=True, word_length=None, separator='  --  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5b275aa6-6d95-4c58-a2c8-8e7e6c83b384",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>569</td>\n",
       "      <td>-1_éducation médias_jeunes_donner_citoyens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "      <td>0_financement_concentration médias_milliardair...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>1_fake news_vérifiée_qualité_plusieurs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>152</td>\n",
       "      <td>2_réseaux sociaux_éducation médias information...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "      <td>3_experts_opinion_différence entre_pensée</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>73</td>\n",
       "      <td>4_sujets_buzz_faits divers_jt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>68</td>\n",
       "      <td>5_analyser_école_apprendre_jeune âge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>56</td>\n",
       "      <td>6_arrêtent_conditionnel_sans_être</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>51</td>\n",
       "      <td>7_presse_acheter_rendre accessible_papier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>8_continu_ue_chaînes information_belges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>46</td>\n",
       "      <td>9_auteurs_financièrement_amendes_diffusant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>10_éthique_charte munich_conseil déontologie_m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>11_anonymat réseaux sociaux_réseaux sociaux in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>12_sanctionner youtube lorsqu_pubs arnaques_mé...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>13_médias locaux_france_national européen lais...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>14_dès école maternelle_permettre enfants_psyc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>15_analyser mieux_suivi_scientifiques_peut perdre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16_emploi temps élèves_élèves_donner moyens pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                               Name\n",
       "0      -1    569         -1_éducation médias_jeunes_donner_citoyens\n",
       "1       0    210  0_financement_concentration médias_milliardair...\n",
       "2       1    178             1_fake news_vérifiée_qualité_plusieurs\n",
       "3       2    152  2_réseaux sociaux_éducation médias information...\n",
       "4       3    118          3_experts_opinion_différence entre_pensée\n",
       "5       4     73                      4_sujets_buzz_faits divers_jt\n",
       "6       5     68               5_analyser_école_apprendre_jeune âge\n",
       "7       6     56                  6_arrêtent_conditionnel_sans_être\n",
       "8       7     51          7_presse_acheter_rendre accessible_papier\n",
       "9       8     47            8_continu_ue_chaînes information_belges\n",
       "10      9     46         9_auteurs_financièrement_amendes_diffusant\n",
       "11     10     45  10_éthique_charte munich_conseil déontologie_m...\n",
       "12     11     24  11_anonymat réseaux sociaux_réseaux sociaux in...\n",
       "13     12     20  12_sanctionner youtube lorsqu_pubs arnaques_mé...\n",
       "14     13     17  13_médias locaux_france_national européen lais...\n",
       "15     14     17  14_dès école maternelle_permettre enfants_psyc...\n",
       "16     15     16  15_analyser mieux_suivi_scientifiques_peut perdre\n",
       "17     16     16  16_emploi temps élèves_élèves_donner moyens pr..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d5f64ad4-cd34-48e5-a02e-017333e9c1cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topic_model.save('models/11-04-2023_bertopic.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c10732",
   "metadata": {},
   "source": [
    "### Explore the model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4a28bde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "# optional\n",
    "topic_model = BERTopic.load('models/13-03-2023_bertopic.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bab0ba77-cc65-43f7-88cc-75b9059dd6f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"1620px\"\n",
       "    height=\"1020\"\n",
       "    src=\"iframe_figures/figure_7.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model = BERTopic.load('models/13-03-2023_bertopic.model')\n",
    "topics_to_merge = [\n",
    "    [3,4,6],[3,15]\n",
    "]\n",
    "topic_model.merge_topics(docs, topics_to_merge)\n",
    "topics_to_merge = [\n",
    "    [4,12]\n",
    "]\n",
    "topic_model.merge_topics(docs, topics_to_merge)\n",
    "barchart = topic_model.visualize_barchart(top_n_topics=17, title=\"<b>Représentation des topics</b>\", width=400, n_words=7)\n",
    "\n",
    "barchart.write_html('topic_visualisations/barchart.html')\n",
    "barchart.show(renderer='iframe_connected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e18feef-144b-44ce-8d07-fd5c7a34e6f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>CustomName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>569</td>\n",
       "      <td>-1_sans_éducation médias_jeunes_donner</td>\n",
       "      <td>-1_sans_éducation médias_jeunes_donner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>0_journalistes_politiques_sujets_débats</td>\n",
       "      <td>L'opinion &amp; le journalisme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>210</td>\n",
       "      <td>1_financement_concentration médias_milliardair...</td>\n",
       "      <td>Financement &amp; indépendance des médias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>178</td>\n",
       "      <td>2_fake news_vérifiée_qualité_plusieurs</td>\n",
       "      <td>Désinformation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>152</td>\n",
       "      <td>3_réseaux sociaux_éducation médias information...</td>\n",
       "      <td>Formation au secondaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>4_esprit_développer_développer esprit critique...</td>\n",
       "      <td>Formation au primaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>5_rendre accessible_papier_abonnements gratuit...</td>\n",
       "      <td>Accès à l'information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "      <td>6_europe_chaînes information continu_france té...</td>\n",
       "      <td>Chaînes d'information en continu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>46</td>\n",
       "      <td>7_news_propos_diffusant_élus</td>\n",
       "      <td>Législation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>8_éthique_charte munich_déontologie journalist...</td>\n",
       "      <td>Éthique du journalisme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>9_anonymat réseaux sociaux_réseaux sociaux int...</td>\n",
       "      <td>Désanoymisation en ligne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>10_sanctionner youtube lorsqu_pubs arnaques_mé...</td>\n",
       "      <td>Arnaques &amp; influenceurs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>11_médias locaux_web_niveau local retrouver_na...</td>\n",
       "      <td>Échelles des médias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>12_emploi temps élèves_emi professeurs_élèves_...</td>\n",
       "      <td>Enseignement &amp; l'EMI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                               Name  \\\n",
       "0      -1    569             -1_sans_éducation médias_jeunes_donner   \n",
       "1       0    263            0_journalistes_politiques_sujets_débats   \n",
       "2       1    210  1_financement_concentration médias_milliardair...   \n",
       "3       2    178             2_fake news_vérifiée_qualité_plusieurs   \n",
       "4       3    152  3_réseaux sociaux_éducation médias information...   \n",
       "5       4     85  4_esprit_développer_développer esprit critique...   \n",
       "6       5     51  5_rendre accessible_papier_abonnements gratuit...   \n",
       "7       6     47  6_europe_chaînes information continu_france té...   \n",
       "8       7     46                       7_news_propos_diffusant_élus   \n",
       "9       8     45  8_éthique_charte munich_déontologie journalist...   \n",
       "10      9     24  9_anonymat réseaux sociaux_réseaux sociaux int...   \n",
       "11     10     20  10_sanctionner youtube lorsqu_pubs arnaques_mé...   \n",
       "12     11     17  11_médias locaux_web_niveau local retrouver_na...   \n",
       "13     12     16  12_emploi temps élèves_emi professeurs_élèves_...   \n",
       "\n",
       "                                CustomName  \n",
       "0   -1_sans_éducation médias_jeunes_donner  \n",
       "1               L'opinion & le journalisme  \n",
       "2    Financement & indépendance des médias  \n",
       "3                           Désinformation  \n",
       "4                  Formation au secondaire  \n",
       "5                    Formation au primaire  \n",
       "6                    Accès à l'information  \n",
       "7         Chaînes d'information en continu  \n",
       "8                              Législation  \n",
       "9                   Éthique du journalisme  \n",
       "10                Désanoymisation en ligne  \n",
       "11                 Arnaques & influenceurs  \n",
       "12                     Échelles des médias  \n",
       "13                    Enseignement & l'EMI  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c3befc9-70fe-4d35-a0b0-f21987627ef5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"3220px\"\n",
       "    height=\"1020\"\n",
       "    src=\"iframe_figures/figure_8.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_labels_dict = {\n",
    "    0:\"L'opinion & le journalisme\",\n",
    "    1:\"Financement & indépendance des médias\",\n",
    "    2:\"Désinformation\",\n",
    "    3:\"Formation au secondaire\",\n",
    "    4:\"Formation au primaire\",\n",
    "    5:\"Accès à l'information\",\n",
    "    6:\"Chaînes d'information en continu\",\n",
    "    7:\"Législation\",\n",
    "    8:\"Éthique du journalisme\",\n",
    "    9:\"Désanoymisation en ligne\",\n",
    "    10:\"Arnaques & influenceurs\",\n",
    "    11:\"Échelles des médias\",\n",
    "    12:\"Enseignement & l'EMI\"   \n",
    "}\n",
    "\n",
    "topic_model.set_topic_labels(topic_labels_dict)\n",
    "barchart = topic_model.visualize_barchart(top_n_topics=17, custom_labels=True, title=\"<b>Représentation des topics</b>\", width=800, n_words=7)\n",
    "\n",
    "barchart.write_html('topic_visualisations/barchart.html')\n",
    "barchart.show(renderer='iframe_connected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d163e65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:05<00:00,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "├─réseaux_professeurs documentalistes_esprit critique_emi_jeunes\n",
      "│    ├─■──esprit_développer_développer esprit critique_analyser_âge ── Topic: 4\n",
      "│    └─réseaux sociaux_professeurs documentalistes_emi_éducation médias information_algorithmes\n",
      "│         ├─■──réseaux sociaux_éducation médias information_professeurs documentalistes_algorithmes_responsables ── Topic: 3\n",
      "│         └─■──emploi temps élèves_emi professeurs_élèves_donner moyens professeurs_enseignement emi ── Topic: 12\n",
      "└─journalistes_média_créer_indépendants_interdire\n",
      "     ├─pubs_arnaques_identité_fake news_auteurs\n",
      "     │    ├─■──anonymat réseaux sociaux_réseaux sociaux interdire_sociaux interdire_supprimer_vrai nom ── Topic: 9\n",
      "     │    └─pubs_arnaques_fake news_auteurs_financièrement\n",
      "     │         ├─■──news_propos_diffusant_élus_sanctionner médias ── Topic: 7\n",
      "     │         └─■──sanctionner youtube lorsqu_pubs arnaques_médias informations_influenceurs_pub institutionnelles déno ── Topic: 10\n",
      "     └─journalistes_média_sources_créer_arrêter\n",
      "          ├─journalistes_média_créer_arrêter_indépendants\n",
      "          │    ├─■──éthique_charte munich_déontologie journalistique_respect_professionnelle ── Topic: 8\n",
      "          │    └─médias_journalistes_arrêter_financement_indépendants\n",
      "          │         ├─journalistes_presse_financement_entre_indépendants\n",
      "          │         │    ├─■──europe_chaînes information continu_france télévision_créer chaine_affranchir ── Topic: 6\n",
      "          │         │    └─journalistes_presse_informations_financement_indépendants\n",
      "          │         │         ├─journalistes_sujets_politique_arrêter_fake news\n",
      "          │         │         │    ├─■──fake news_vérifiée_qualité_plusieurs_sources information ── Topic: 2\n",
      "          │         │         │    └─■──journalistes_politiques_sujets_débats_arrêtent ── Topic: 0\n",
      "          │         │         └─■──financement_concentration médias_milliardaires_interdire_grands groupes ── Topic: 1\n",
      "          │         └─■──rendre accessible_papier_abonnements gratuits_beaucoup_établissements scolaires ── Topic: 5\n",
      "          └─■──médias locaux_web_niveau local retrouver_nationales internationales publier_notoriété légitimité moi ── Topic: 11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hierarchical_topics = topic_model.hierarchical_topics(docs)\n",
    "\n",
    "tree = topic_model.get_topic_tree(hierarchical_topics)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9a4d712",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:05<00:00,  2.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"1220px\"\n",
       "    height=\"415\"\n",
       "    src=\"iframe_figures/figure_13.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hierarchical_topics = topic_model.hierarchical_topics(docs)\n",
    "\n",
    "hierarchy = topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics, width=1200, custom_labels=topic_labels_dict)\n",
    "\n",
    "hierarchy.write_html('topic_visualisations/hierarchy.html')\n",
    "hierarchy.show(renderer='iframe_connected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "949ace67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"1220px\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_15.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmap = topic_model.visualize_heatmap(n_clusters=6, custom_labels=topic_labels_dict, width=1200)\n",
    "\n",
    "heatmap.write_html('topic_visualisations/heatmap.html')\n",
    "heatmap.show(renderer='iframe_connected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "78bf41be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"520\"\n",
       "    src=\"iframe_figures/figure_95.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.visualize_term_rank(log_scale=True).show(renderer='iframe_connected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efde642d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"670px\"\n",
       "    height=\"670\"\n",
       "    src=\"iframe_figures/figure_16.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_model.visualize_topics().show(renderer='iframe_connected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab85f6cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/kelly.christensen/.cache/torch/sentence_transformers/dangvantuan_sentence-camembert-large. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b2504ca8e0481d9efecd45b6e83ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/kelly.christensen/.cache/torch/sentence_transformers/dangvantuan_sentence-camembert-large. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "from umap import UMAP\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(\"dangvantuan/sentence-camembert-large\")\n",
    "embeddings = camembert_sentence_transformer.encode(docs, show_progress_bar=True)\n",
    "\n",
    "camembert_sentence_transformer = SentenceTransformer(\"dangvantuan/sentence-camembert-large\")\n",
    "reduced_embeddings = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95c4e19e-808d-4736-9a5f-893939675543",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"1820px\"\n",
       "    height=\"770\"\n",
       "    src=\"iframe_figures/figure_20.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_visualisation = topic_model.visualize_documents(docs=docs, reduced_embeddings=reduced_embeddings, width=1800, height=750, sample=0.1, custom_labels=topic_labels_dict)\n",
    "\n",
    "\n",
    "doc_visualisation.write_html('topic_visualisations/doc_visualisation.html')\n",
    "doc_visualisation.show(renderer='iframe_connected')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0f5b55",
   "metadata": {},
   "source": [
    "Print the results to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "689716ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import casanova\n",
    "\n",
    "PREDICTIONS_FILE = 'bertopic_topics_notebook.csv'\n",
    "\n",
    "results = topic_model.get_document_info(docs=docs)\n",
    "results.to_csv()\n",
    "with open(DATAFILE) as f, open(PREDICTIONS_FILE, 'w') as of:\n",
    "    enricher = casanova.enricher(f, of, add=[\"document\", \"topic\", \"name\", \"custom_name\", \"top_n_words\", \"probability\", \"representative_document\"])\n",
    "    for i, row in enumerate(enricher):\n",
    "        enricher.writerow(row=row, add=[results[\"Document\"][i], results[\"Topic\"][i], results[\"Name\"][i], results[\"CustomName\"][i], results[\"Top_n_words\"][i], results[\"Probability\"][i], results[\"Representative_document\"][i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb76ecc1",
   "metadata": {},
   "source": [
    "# Visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9463d5c1",
   "metadata": {},
   "source": [
    "In a dictionary, index the documents and their metadata by each document's Id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e7ccda1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(PREDICTIONS_FILE) as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        doc_index = {row[\"Id\"]:row for row in reader}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fbeba9",
   "metadata": {},
   "source": [
    "While parsing the matrix file, create nodes and edges and label them with data from the topic predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4efd96d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MATRIX_FILE = 'defacto_covotes.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70f74086",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from statistics import mean\n",
    "import casanova\n",
    "\n",
    "with open(MATRIX_FILE) as f:\n",
    "    reader = casanova.reader(f)\n",
    "    pid1_pos = reader.headers['pid1']\n",
    "    pid2_pos = reader.headers['pid2']\n",
    "    vote1_pos = reader.headers['vote1']\n",
    "    vote2_pos = reader.headers['vote2']\n",
    "    count_pos = reader.headers['count']\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    for row in reader:\n",
    "        pid1 = row[pid1_pos]\n",
    "        pid2 = row[pid2_pos]\n",
    "\n",
    "        # If the matrix refers to documents not in the original data, skip \n",
    "        if not doc_index.get(pid1) or not doc_index.get(pid2):\n",
    "            continue\n",
    "\n",
    "        # Base an edge's weight on the support that two related propositions received\n",
    "        average_nb_votes = mean([int(doc_index[pid1][\"Nb de votes\"]), int(doc_index[pid2][\"Nb de votes\"])])\n",
    "        weight = int(row[count_pos])/average_nb_votes\n",
    "\n",
    "        # Unless already added to the Graph, add both nodes in the matrix row and create an edge between them\n",
    "        print(doc_index[pid1])\n",
    "        if not G.has_node(pid1) and not str(doc_index[pid1][\"topic\"]) == \"-1\":\n",
    "            G.add_node(pid1, label=doc_index[pid1][\"Proposition\"], **doc_index[pid1])\n",
    "\n",
    "        if not G.has_node(pid2) and not str(doc_index[pid2][\"topic\"]) == \"-1\":\n",
    "            G.add_node(pid2, label=doc_index[pid2][\"Proposition\"], **doc_index[pid2])\n",
    "\n",
    "        if row[vote1_pos] == row[vote2_pos]:  # To-do: test if we can try all 3 types of cases\n",
    "            G.add_edge(pid1, pid2, weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pelote\n",
    "\n",
    "GEFX_FILE = 'sparsification.gexf'\n",
    "\n",
    "H = pelote.multiscale_backbone(G, alpha=0.05)\n",
    "nx.write_gexf(H, GEFX_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0319d78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from ipysigma import Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f3e7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing a gexf graph\n",
    "g = nx.read_gexf(GEFX_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6bc506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the graph with a size mapped on degree and\n",
    "# a color mapped on a categorical attribute of the nodes\n",
    "Sigma(g, node_size=g.degree, node_color='topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e0445d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
